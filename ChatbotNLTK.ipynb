{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained on the Wiki QnA dataset, this chatbot attempts to return a common FAQ about your topic of interest. \n",
    "\n",
    "Ask about keywords like: American Civil War, Season, Traffic light, Black pepper, United States, Harry Potter, Data Warehouse, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T20:20:04.069963Z",
     "start_time": "2020-03-31T20:20:00.748313Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np\n",
    "import random \n",
    "import string \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T20:20:05.120756Z",
     "start_time": "2020-03-31T20:20:04.073168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nikhilkumarjha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nikhilkumarjha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import the TFidf vectorizer to convert a collection of raw documents to a matrix of TF-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# use cosine similarity concept to generate a response from the bot by comparing the similarity between user input and the data present in the corpus\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Use wikipedia QnA data as corpus\n",
    "filename = \"WikiQnA.txt\"\n",
    "\n",
    "f = open(filename, 'r', errors='ignore')\n",
    "raw_text = f.read()\n",
    "\n",
    "raw_text=raw_text.lower()\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# convert to list of sentences\n",
    "sentence_tokens = nltk.sent_tokenize(raw_text)\n",
    "# print(type((sentence_tokens)))\n",
    "# print(len((sentence_tokens)))\n",
    "# print(sentence_tokens[:5])\n",
    "\n",
    "# convert to list of words\n",
    "word_tokens = nltk.word_tokenize(raw_text)\n",
    "# print(type((word_tokens)))\n",
    "# print(len(word_tokens))\n",
    "# print(word_tokens[:5])\n",
    "\n",
    "# We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens.\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punctuation_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_dict)))\n",
    "\n",
    "# The bot should return a greeting if the user input is a greeting\n",
    "greeting_input = [\"hi\", \"hello\", \"what's up\", \"hola\", \"hey\", \"how are you\"]\n",
    "\n",
    "greeting_response = [\"hi\", \"hello\", \"what's up\", \"hola\", \"hey\", \"hi there\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in greeting_input:\n",
    "            return random.choice(greeting_response)\n",
    "\n",
    "# The user enters an utterance and the bot tries to return an appropriate response using known information from the corpus, else it says \"Sorry, I didn't understand that\"\n",
    "def response(user_input):\n",
    "    bot_response = \"\"\n",
    "    sentence_tokens.append(user_input)\n",
    "#     print(sentence_tokens)\n",
    "    \n",
    "    TfidVect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    TfidFit = TfidVect.fit_transform(sentence_tokens)\n",
    "    \n",
    "    vals = cosine_similarity(TfidFit[-1], TfidFit)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    \n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_TfidFit = flat[-2]\n",
    "    \n",
    "    if req_TfidFit==0:\n",
    "        bot_response = bot_response + \"Sorry, I didn't understand!\\n\"\n",
    "        return bot_response\n",
    "    else:\n",
    "        bot_response = bot_response + sentence_tokens[idx]\n",
    "        return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-31T20:20:00.648Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: \n",
      "My name is BOT. Chat-BOT (*suspense music in the background*). \n",
      "I will tell you about some common FAQs about various topics. \n",
      "If you wish to quit, simply type bye!\n",
      "\n",
      "\n",
      "hello\n",
      "\n",
      "BOT: \n",
      "hey\n",
      "do you know kirk douglas\n",
      "\n",
      "BOT: Here is a popular FAQ related to your query\n",
      " \"how old is kirk douglas, the actor?\n",
      "\n",
      "harry potter \n",
      "\n",
      "BOT: Here is a popular FAQ related to your query\n",
      " who played dumbledore in harry potter :- dumbledore is portrayed by richard harris in the film adaptions of harry potter and the philosopher's stone and harry potter and the chamber of secrets .\n",
      "\n",
      "dexter\n",
      "\n",
      "BOT: Here is a popular FAQ related to your query\n",
      " \"what season is  dexter on :- after months of rumors, on april 18, 2013, showtime announced via social media that season eight would be the final season of dexter.\"\n",
      "\n",
      "american civil war\n",
      "\n",
      "BOT: Here is a popular FAQ related to your query\n",
      " \"when did the civil war start and where :- the american civil war (acw), also known as the war between the states or simply the civil war (see naming ), was a civil war fought from 1861 to 1865 between the united states (the \"\"union\"\" or the \"\"north\"\") and several southern slave states that declared their secession and formed the confederate states of america (the \"\"confederacy\"\" or the \"\"south\"\").\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some minor tweaks regarding what the bot should say while starting and ending the convo\n",
    "flag = True\n",
    "print(\"BOT: \\nMy name is BOT. Chat-BOT (*suspense music in the background*). \\nI will tell you about some common FAQs about various topics. \\nIf you wish to quit, simply type bye!\\n\\n\")\n",
    "\n",
    "while flag==True:\n",
    "    user_input = input()\n",
    "    user_input = user_input.lower()\n",
    "    if user_input not in [\"bye\", \"quit\", \"exit\"]:\n",
    "        if user_input in [\"thanks\", \"thank you\", \"danke\"]:\n",
    "            flag = False\n",
    "            print(\"\\nBOT: You are very much welcome!\")\n",
    "        else: \n",
    "            if greeting(user_input) != None:\n",
    "                print(\"\\nBOT: \\n\" + greeting(user_input))\n",
    "            else:\n",
    "                print(\"\\nBOT: Here is a popular FAQ related to your query\\n\", response(user_input) + \"\\n\")\n",
    "                sentence_tokens.remove(user_input)\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Bot: Bye! See you soon.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T18:05:32.487883Z",
     "start_time": "2020-03-31T18:05:32.427647Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T17:50:13.623012Z",
     "start_time": "2020-03-31T17:50:13.604504Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
